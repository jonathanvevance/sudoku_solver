{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.base import clone\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift (Augment) images by 1 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding dataset\n",
    "square_size = 28\n",
    "def nudge_image(X):\n",
    "    \"\"\"\n",
    "    This produces a list of np.array 5 times bigger than the original image \n",
    "    (np array), by moving the image around by 1px to left, right, down and up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]\n",
    "    ]\n",
    "\n",
    "    def shift(x, w):\n",
    "        return convolve(x.reshape((square_size, square_size)), mode='constant', weights = w)\n",
    "\n",
    "    X = ([X] + [shift(X, vector) for vector in direction_vectors])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit: 9, image: 133 / 134                                                                                                                                                     "
     ]
    }
   ],
   "source": [
    "curdir = os.getcwd()\n",
    "dataset_dir = os.path.join(curdir, 'sudoku_dataset')\n",
    "    \n",
    "# extending train set\n",
    "y_train = np.empty((0, 1), int)\n",
    "X_train = np.empty((0, square_size * square_size), float)\n",
    "\n",
    "for digit in range(1, 10):\n",
    "    data_dir =  os.path.join(dataset_dir, 'train/' + str(digit))\n",
    "    length = len(os.listdir(data_dir))\n",
    "    for idx, entry in enumerate(os.scandir(data_dir)):\n",
    "        \n",
    "        print(f\"\\rdigit: {digit}, image: {idx} / {length}\", end = \" \")\n",
    "        if (entry.path.endswith(\".jpg\") and entry.is_file()):\n",
    "            \n",
    "            img = cv2.imread(entry.path, 0)        \n",
    "            extended_imgs = nudge_image(img)\n",
    "            for img_mod in extended_imgs:\n",
    "                y_train = np.vstack((y_train, digit))\n",
    "                X_train = np.vstack((X_train, img_mod.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({8: 785, 3: 765, 1: 705, 9: 670, 4: 665, 5: 650, 7: 650, 2: 620, 6: 560})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit: 9, image: 44 / 45                                                                                                                            "
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join(curdir, 'sudoku_dataset')\n",
    "\n",
    "# extending test\n",
    "y_test = np.empty((0, 1), int)\n",
    "X_test = np.empty((0, square_size * square_size), float)\n",
    "\n",
    "for digit in range(1, 10):\n",
    "    data_dir =  os.path.join(dataset_dir, 'test/' + str(digit))\n",
    "    length = len(os.listdir(data_dir))\n",
    "    for idx, entry in enumerate(os.scandir(data_dir)):\n",
    "        \n",
    "        print(f\"\\rdigit: {digit}, image: {idx} / {length}\", end = \" \")\n",
    "        if (entry.path.endswith(\".jpg\") and entry.is_file()):\n",
    "            \n",
    "            img = cv2.imread(entry.path, 0)        \n",
    "            extended_imgs = nudge_image(img)\n",
    "            for img_mod in extended_imgs:\n",
    "                y_test = np.vstack((y_test, digit))\n",
    "                X_test = np.vstack((X_test, img_mod.ravel()))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 260, 8: 255, 1: 235, 5: 235, 9: 225, 2: 220, 4: 215, 7: 215, 6: 190})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_test[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling to (0, 1] range\n",
    "X_test = (X_test - np.min(X_test, 0)) / (np.max(X_test, 0) + 0.0001)\n",
    "X_train = (X_train - np.min(X_train, 0)) / (np.max(X_train, 0) + 0.0001)\n",
    "\n",
    "# random shuffling\n",
    "p_test = np.random.permutation(len(X_test))\n",
    "X_test, y_test = X_test[p_test], y_test[p_test]\n",
    "\n",
    "p_train = np.random.permutation(len(X_train))\n",
    "X_train, y_train = X_train[p_train], y_train[p_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RBM + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = BernoulliRBM(random_state = 0, verbose=True)\n",
    "logistic = linear_model.LogisticRegression(solver = 'newton-cg', tol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm_features_classifier = Pipeline(\n",
    "    steps=[('rbm', rbm), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.n_iter = 15\n",
    "logistic.C = 6000\n",
    "rbm.n_components = 100\n",
    "rbm.learning_rate = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -86.83, time = 0.92s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.04, time = 1.08s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -65.14, time = 1.03s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -64.69, time = 0.85s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -60.75, time = 0.89s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -68.98, time = 0.82s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -61.77, time = 0.84s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -53.91, time = 0.87s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -56.37, time = 0.84s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -53.33, time = 0.89s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -56.34, time = 0.89s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -51.67, time = 0.93s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -52.34, time = 0.86s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -51.42, time = 0.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('rbm',\n",
       "                 BernoulliRBM(batch_size=10, learning_rate=0.06,\n",
       "                              n_components=100, n_iter=15, random_state=0,\n",
       "                              verbose=True)),\n",
       "                ('logistic',\n",
       "                 LogisticRegression(C=6000, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='newton-cg', tol=1, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm_features_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression using RBM features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.99      0.98       235\n",
      "           2       0.97      0.95      0.96       220\n",
      "           3       0.99      1.00      1.00       260\n",
      "           4       0.97      0.97      0.97       215\n",
      "           5       0.95      0.98      0.96       235\n",
      "           6       0.96      0.88      0.92       190\n",
      "           7       1.00      0.97      0.98       215\n",
      "           8       0.95      0.99      0.97       255\n",
      "           9       0.97      0.98      0.97       225\n",
      "\n",
      "    accuracy                           0.97      2050\n",
      "   macro avg       0.97      0.97      0.97      2050\n",
      "weighted avg       0.97      0.97      0.97      2050\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = rbm_features_classifier.predict(X_test)\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'sudoku_model.pkl'\n",
    "pickle.dump(rbm_features_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
